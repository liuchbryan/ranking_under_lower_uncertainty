{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from rulu.bootstrap_CI_test import *\n",
    "from rulu.normal_normal_model import get_samples\n",
    "from rulu.utils import get_test_params, find_all_tests_in_same_category\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import percentileofscore\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_collection_result(test_collection: List[BootstrapCITest]) -> None:\n",
    "    if test_collection is None or len(test_collection) == 0:\n",
    "        print(\"There is nothing in the provided test collection.\")\n",
    "        return\n",
    "\n",
    "    within_CI = [test.theoretical_quantity_in_sample_CI()\n",
    "                 for test in test_collection]\n",
    "\n",
    "    print(test_collection[0].test_name() +\n",
    "          \": {}/{} ({}%) \"\n",
    "          .format(np.sum(within_CI), len(within_CI),\n",
    "                  np.round(100.0 * np.sum(within_CI) / len(within_CI), 2)) +\n",
    "          \"of the tests have the theoretical quantity within the CI.\")\n",
    "\n",
    "\n",
    "def save_test_collection(test_collection: List[BootstrapCITest], in_dir: str = './output/') -> None:\n",
    "    \"\"\"\n",
    "    Save given `test_collection` as a pickle file in `in_dir`\n",
    "    :param test_collection: List of tests\n",
    "    :param in_dir: Output directory\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if test_collection is None or len(test_collection) == 0:\n",
    "        return\n",
    "\n",
    "    file_name = (in_dir + str(test_collection[0].__class__.__name__) +\n",
    "                 \"_\" + str(int(time.time())) + \".pickle\")\n",
    "    pickle_file = open(file_name, 'wb')\n",
    "    pickle.dump(test_collection, pickle_file)\n",
    "\n",
    "    print(\"The test collection is saved at \" + file_name)\n",
    "\n",
    "\n",
    "def find_all_tests_in_same_category(test, in_dir='../output'):\n",
    "    \"\"\"\n",
    "    Retrieve all tests in `in_dir` that is of the same type as the specified `test`\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_tests_from_pickle_file(file_path):\n",
    "        filehandler = open(file_path, 'rb')\n",
    "        return pickle.load(filehandler)\n",
    "    \n",
    "    tests_pickle_fps = [\n",
    "        os.path.join(in_dir, file)\n",
    "        for file in os.listdir(in_dir) \n",
    "        if str(test.__class__.__name__) in file]\n",
    "    \n",
    "    return [test for tests in map(get_tests_from_pickle_file, tests_pickle_fps)\n",
    "            for test in tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = 100\n",
    "num_runs = 10000\n",
    "BOOTSTRAP_BATCH_SIZE = 100\n",
    "num_bootstrap_samples = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1/100 (N=14, M=7): Done.                                         \n",
      "Test 2/100 (N=11, M=5): Done.                                         \n",
      "Test 3/100 (N=178, M=45): Done.                                         \n",
      "Test 4/100 (N=120, M=32): Done.                                         \n",
      "Test 5/100 (N=19, M=6): Done.                                         \n",
      "Test 6/100 (N=503, M=341): Done.                                         \n",
      "Test 7/100 (N=2512, M=858): Done.                                         \n",
      "Test 8/100 (N=220, M=164): Done.                                         \n",
      "Test 9/100 (N=2642, M=1643): Done.                                         \n",
      "Test 10/100 (N=309, M=76): Done.                                         \n",
      "Test 11/100 (N=1511, M=595): Done.                                         \n",
      "Test 12/100 (N=918, M=714): Done.                                         \n",
      "Test 13/100 (N=36, M=17): Done.                                         \n",
      "Test 14/100 (N=569, M=27): Done.                                         \n",
      "Test 15/100 (N=890, M=378): Done.                                         \n",
      "Test 16/100 (N=351, M=172): Done.                                         \n",
      "Test 17/100 (N=16, M=5): Done.                                         \n",
      "Test 18/100 (N=1882, M=1320): Done.                                         \n",
      "Test 19/100 (N=153, M=11): Done.                                         \n",
      "Test 20/100 (N=303, M=168): Done.                                         \n",
      "Test 21/100 (N=10, M=7): Done.                                         \n",
      "Test 22/100 (N=143, M=109): Done.                                         \n",
      "Test 23/100 (N=360, M=53): Done.                                         \n",
      "Test 24/100 (N=2723, M=1726): Done.                                         \n",
      "Test 25/100 (N=1565, M=1151): Done.                                         \n",
      "Test 26/100 (N=27, M=13): Done.                                         \n",
      "Test 27/100 (N=28, M=11): Done.                                         \n",
      "Var(V): 20/27 (74.07%) of the tests have the theoretical quantity within the CI.\n",
      "The test collection is saved at ./output/VarVCITest_1577927203.pickle\n",
      "Cov(V1, V2): 0/27 (0.0%) of the tests have the theoretical quantity within the CI.\n",
      "The test collection is saved at ./output/CovV1V2CITest_1577930827.pickle\n",
      "Var(D): 0/27 (0.0%) of the tests have the theoretical quantity within the CI.\n",
      "The test collection is saved at ./output/VarDCITest_1577930830.pickle\n"
     ]
    }
   ],
   "source": [
    "# Prepare test collections\n",
    "var_V_tests = []\n",
    "cov_V1_V2_tests = []\n",
    "var_D_tests = []\n",
    "\n",
    "bootstrap_test_collections = [\n",
    "    var_V_tests,\n",
    "    cov_V1_V2_tests,\n",
    "    var_D_tests\n",
    "]\n",
    "\n",
    "for num_test in range(0, num_tests):\n",
    "    try:\n",
    "        # Sample the parameters from a realistic parameter space\n",
    "        params = get_test_params()\n",
    "        N = int(params['N'])\n",
    "        M = int(params['M'])\n",
    "        mu_X = params['mu_X']\n",
    "        mu_epsilon = params['mu_epsilon']\n",
    "        sigma_sq_X = params['sigma_sq_X']\n",
    "        sigma_sq_1 = params['sigma_sq_1']\n",
    "        sigma_sq_2 = params['sigma_sq_2']\n",
    "        r = params['r']\n",
    "        s = params['s']\n",
    "\n",
    "        # Prepare a test\n",
    "        var_V_test = VarVCITest(sigma_sq_X, N, M, sigma_sq_1=sigma_sq_1)\n",
    "        cov_V1_V2_test = CovV1V2CITest(sigma_sq_X, sigma_sq_1, sigma_sq_2, N, M)\n",
    "        var_D_test = VarDCITest(sigma_sq_X, sigma_sq_1, sigma_sq_2, N, M)\n",
    "\n",
    "        # Arrange the covariance tests IN THE SAME ORDER as that in the collections\n",
    "        bootstrap_tests = [var_V_test,\n",
    "                           cov_V1_V2_test,\n",
    "                           var_D_test\n",
    "                          ]\n",
    "        \n",
    "        # Get the initial samples\n",
    "        print(\"Test {}/{} (N={}, M={}): calculating initial samples...    \"\n",
    "              .format(num_test + 1, num_tests, N, M),\n",
    "              end='\\r')\n",
    "        \n",
    "        samples = get_samples(num_runs, N, M, mu_X, mu_epsilon,\n",
    "                              sigma_sq_X, sigma_sq_1, sigma_sq_2,\n",
    "                              verbose=False, r=r, s=s)\n",
    "        \n",
    "        for test in bootstrap_tests:\n",
    "            test.set_initial_samples(samples)\n",
    "        \n",
    "        #Â Bootstrap from the initial samples in batches\n",
    "        for i in range(0, int(num_bootstrap_samples / BOOTSTRAP_BATCH_SIZE)):\n",
    "            print(\"Test {}/{} (N={}, M={}): calculating bootstrap samples {}/{}...    \"\n",
    "                  .format(num_test + 1, num_tests, N, M,\n",
    "                          i * BOOTSTRAP_BATCH_SIZE, num_bootstrap_samples),\n",
    "                  end='\\r')\n",
    "            \n",
    "            for test in bootstrap_tests:\n",
    "                test.generate_bootstrap_samples(BOOTSTRAP_BATCH_SIZE)\n",
    "        \n",
    "        # Generate bootstrap samples that can't fit in a batch\n",
    "        for test in bootstrap_tests:\n",
    "                test.generate_bootstrap_samples(num_bootstrap_samples % BOOTSTRAP_BATCH_SIZE)\n",
    "\n",
    "        # Once a test is completed (i.e. we collected enough covariate\n",
    "        # samples), we added them to the corresponding, existing\n",
    "        # collection of tests\n",
    "        for (bootstrap_test, bootstrap_test_collection) in \\\n",
    "                [(bootstrap_tests[i], bootstrap_test_collections[i]) \n",
    "                 for i in range(0, len(bootstrap_tests))]:\n",
    "            bootstrap_test_collection.append(bootstrap_test)\n",
    "                        \n",
    "        print(\"Test {}/{} (N={}, M={}): Done.                                         \"\n",
    "              .format(num_test + 1, num_tests, N, M))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # Breaking the for loop is sufficient, as we want to\n",
    "        # analyse the results accumulated so far\n",
    "        break\n",
    "\n",
    "# Print some statistics and save the test collections for future reference\n",
    "# once we reached the number of experiments / process is interrupted\n",
    "for bootstrap_test_collection in bootstrap_test_collections:\n",
    "    try:\n",
    "        print_test_collection_result(bootstrap_test_collection)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"{}: Skipped.\".format(bootstrap_test_collection[0].test_name()))\n",
    "    save_test_collection(bootstrap_test_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test collection is saved at ./output/bootstrap_CI_tests/VarVCITest_1577960139.pickle\n",
      "The test collection is saved at ./output/bootstrap_CI_tests/CovV1V2CITest_1577960141.pickle\n",
      "The test collection is saved at ./output/bootstrap_CI_tests/VarDCITest_1577960145.pickle\n"
     ]
    }
   ],
   "source": [
    "for bootstrap_test_collection in bootstrap_test_collections:\n",
    "    save_test_collection(bootstrap_test_collection, in_dir=\"./output/bootstrap_CI_tests/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating theoretical quantity / sample CI for test 6/27...\r"
     ]
    }
   ],
   "source": [
    "examples = find_all_tests_in_same_category(VarVCITest(sigma_sq_1=0.5**2), in_dir='./output/bootstrap_CI_tests/')\n",
    "for test in examples:\n",
    "    test.theoretical_quantity_cache = None\n",
    "\n",
    "print_test_collection_result(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_sample_percentile = [test.theoretical_quantity_sample_percentile() for test in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(theoretical_sample_percentile, bins=range(0, 105, 5))\n",
    "plt.xlim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
